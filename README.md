# Multi stage attention U-net for fundus imaging segmentation
# Introduction
Fundus imaging segmentation plays a key role during ophthalmic diseases diagnosis. While manually segmentation is a time-consuming task and demands a specialist, in the last years an undefined number of works have been developed to automatically identify ocular structures and speed this task.

Here I propose a multi-stage and multi-task attention U-net for vessel, optic disc and optic disc cup segmentation in fundus images. It a 3-train stage model, each with a different loss function (BCE, Tversky and FocalTversky). This approach aims progressive learning and better generalization to improve the segmentation quality. 

The model was tested in the following well stablished datasets: 

- Optic disc: [DRIONS-DB](https://www.sciencedirect.com/science/article/pii/S0933365708000547), [Drishti](https://ieeexplore.ieee.org/abstract/document/6867807) and [REFUGE](https://www.sciencedirect.com/science/article/pii/S1361841519301100).
- Optic dis cup: Drishti and REFUGE (same references of optic disc cup).
- Vessels: [CHASE](https://ieeexplore.ieee.org/document/6224174), [DRIVE](https://ieeexplore.ieee.org/abstract/document/845178), [FIVES](https://www.nature.com/articles/s41597-022-01564-3), [HRF](https://www5.cs.fau.de/research/data/fundus-images/) and [STARE](https://ieeexplore.ieee.org/abstract/document/845178).

These datasets were split in train and test datasets and trained during 50 epochs. To prevent overfitting, it was performed drop-out and early stopping. The results were evaluated in terms of Dice (F1)-score, accuracy, precision, recall and specificity. 

An overview the results as well evaluation metrics and losses are shown in the Results section. For a more detailed view of individual results, assess the results folder (including alson ROC).


# Folder structure:
```
Multi-stage-attention-u-net-for-fundus-imaging-segmentation/
├── figures/                                             # Figures showed in .md files
│   ├── dice_OD.png
│   ├── dice_OD_cup.png
│   ├── dice_vessels.png
│   ├── loss_OD.png
│   ├── loss_OD_cup.png
│   ├── loss_vessels.png
│
├── outputs/                                            # Saved outputs generated by the model for different datasets (the model also saves .pth files however they are not included due their large size)
│   ├── CHASE/                                          # Outputs from CHASE dataset
│   │  ├── curves/                                      # Plots of metrics generated by the model for different stages.
│   │  │    ├── BCE/
│   │  │    │    ├── roc_curve.png
│   │  │    │    ├── training_curves.png                # Dice coefficient and loss plotted together
│   │  │    ├── FocalTversky/                           # Same structure as BCE
│   │  │    ├── Tversky/                                # Same structure as BCE
│   │  ├── metrics/                                     # .npy files with metrics generated by the model for different stages.
│   │  │    ├── BCE/                                    # Includes in the following order: accuracy, best dice history, f1-score, precision, recall, specificity, train dices, train losses, validation dices, validation losses (all over epochs), y predicted and y true from ROC
│   │  │    ├── FocalTversky/                           # Same structure as BCE
│   │  │    ├── Tversky/                                # Same structure as BCE
│   │  ├── preds/                                       # Saved images
│   │  │    ├── BCE/                                    # Saved images of orignal image, mask and model prediction for 6 samples
│   │  │    ├── FocalTversky/                           # Same structure as BCE
│   │  │    ├── Tversky/                                # Same structure as BCE
           .
           .
           .                        
├── utils/                                              # Utilities
│   ├── augmentation.py                                 # Perform data augmentation
│   ├── dataset.py                                      # Prepare the dataset
│   ├── evalmetrics.py                                  # Metrics used to evaluate the model performance
│   ├── losses.py                                       # Losses functions used for the different train stages
│   ├── plot_curves.py                                  # Plots and saves the evaluation metrics
│   ├── show_predictions.py                             #  Plots and saves outputs for 6 samples
│   ├── train.py                                        # Function to train the model
├── main.py                                             # Run the algorithm
├── model.py                                            # Attention U-net model used in this project
├── README.md


```

# How to use:
- After the download set the work directory to the project folder;
- Set the dataset_images and dataset_masks with the images and masks;
  - Images and masks should be same name and format (accepted formats are: .png, .jpg, .jpeg and .tif)
- Set the number of epochs and patience (for early stopping)

# Results:

